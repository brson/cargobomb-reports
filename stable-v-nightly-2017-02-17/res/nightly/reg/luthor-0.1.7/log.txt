boom! testing luthor-0.1.7 against nightly for nightly
boom! running: cargo +nightly build --frozen
boom! creating container for: cargo +nightly build --frozen
boom! running `docker create -v /home/ec2-user/cargobomb/./work/local/test-source/nightly/nightly:/source:ro -v /home/ec2-user/cargobomb/./work/local/cargo-home:/cargo-home:ro -v /home/ec2-user/cargobomb/./work/local/rustup-home:/rustup-home:ro -v /home/ec2-user/cargobomb/./work/local/target-dirs/nightly/nightly:/target:rw -e USER_ID=500 -e CMD=cargo +nightly build --frozen cargobomb`
blam! 7bc228480faab03e719864d781d2416cee18f94c78a0af593af3bfce16387b72
boom! running `docker start -a 7bc228480faab03e719864d781d2416cee18f94c78a0af593af3bfce16387b72`
kablam!    Compiling luthor v0.1.7 (file:///source)
kablam! warning: function is never used: `argument`
kablam!    --> src/lexers/coffeescript.rs:188:1
kablam!     |
kablam! 188 | fn argument(tokenizer: &mut Tokenizer) -> Option<StateFunction> {
kablam!     | ^
kablam!     |
kablam!     = note: #[warn(dead_code)] on by default
kablam! 
kablam! warning: function is never used: `function`
kablam!    --> src/lexers/coffeescript.rs:256:1
kablam!     |
kablam! 256 | fn function(tokenizer: &mut Tokenizer) -> Option<StateFunction> {
kablam!     | ^
kablam!     |
kablam!     = note: #[warn(dead_code)] on by default
kablam! 
kablam!     Finished dev [unoptimized + debuginfo] target(s) in 1.48 secs
boom! running `docker rm -f 7bc228480faab03e719864d781d2416cee18f94c78a0af593af3bfce16387b72`
blam! 7bc228480faab03e719864d781d2416cee18f94c78a0af593af3bfce16387b72
boom! running: cargo +nightly test --frozen --no-run
boom! creating container for: cargo +nightly test --frozen --no-run
boom! running `docker create -v /home/ec2-user/cargobomb/./work/local/test-source/nightly/nightly:/source:ro -v /home/ec2-user/cargobomb/./work/local/cargo-home:/cargo-home:ro -v /home/ec2-user/cargobomb/./work/local/rustup-home:/rustup-home:ro -v /home/ec2-user/cargobomb/./work/local/target-dirs/nightly/nightly:/target:rw -e USER_ID=500 -e CMD=cargo +nightly test --frozen --no-run cargobomb`
blam! 5e121adb05930260d34f176bfc3f9c7459aa4c06a76d6b7a30275eeab22e1b40
boom! running `docker start -a 5e121adb05930260d34f176bfc3f9c7459aa4c06a76d6b7a30275eeab22e1b40`
kablam!    Compiling luthor v0.1.7 (file:///source)
kablam! warning: function is never used: `argument`
kablam!    --> src/lexers/coffeescript.rs:188:1
kablam!     |
kablam! 188 | fn argument(tokenizer: &mut Tokenizer) -> Option<StateFunction> {
kablam!     | ^
kablam!     |
kablam!     = note: #[warn(dead_code)] on by default
kablam! 
kablam! warning: function is never used: `function`
kablam!    --> src/lexers/coffeescript.rs:256:1
kablam!     |
kablam! 256 | fn function(tokenizer: &mut Tokenizer) -> Option<StateFunction> {
kablam!     | ^
kablam!     |
kablam!     = note: #[warn(dead_code)] on by default
kablam! 
kablam!     Finished dev [unoptimized + debuginfo] target(s) in 2.77 secs
boom! running `docker rm -f 5e121adb05930260d34f176bfc3f9c7459aa4c06a76d6b7a30275eeab22e1b40`
blam! 5e121adb05930260d34f176bfc3f9c7459aa4c06a76d6b7a30275eeab22e1b40
boom! running: cargo +nightly test --frozen
boom! creating container for: cargo +nightly test --frozen
boom! running `docker create -v /home/ec2-user/cargobomb/./work/local/test-source/nightly/nightly:/source:ro -v /home/ec2-user/cargobomb/./work/local/cargo-home:/cargo-home:ro -v /home/ec2-user/cargobomb/./work/local/rustup-home:/rustup-home:ro -v /home/ec2-user/cargobomb/./work/local/target-dirs/nightly/nightly:/target:rw -e USER_ID=500 -e CMD=cargo +nightly test --frozen cargobomb`
blam! 84ffc465f05ac96d4fbf88741c647d520a94a9f36529832ab4e619b299bcb027
boom! running `docker start -a 84ffc465f05ac96d4fbf88741c647d520a94a9f36529832ab4e619b299bcb027`
kablam!     Finished dev [unoptimized + debuginfo] target(s) in 0.0 secs
kablam!      Running /target/debug/deps/luthor-606bcd27bd1eee85
blam! 
blam! running 27 tests
blam! test lexers::coffeescript::tests::it_identifies_integers_and_operators ... ok
blam! test lexers::html_erb::tests::it_works ... ok
blam! test lexers::default::tests::it_works ... ok
blam! test lexers::javascript::tests::it_identifies_integers_and_operators ... ok
blam! test lexers::coffeescript::tests::it_works ... ok
blam! test lexers::json::tests::it_can_handle_garbage ... ok
blam! test lexers::javascript::tests::it_works ... ok
blam! test lexers::json::tests::it_can_handle_open_strings ... ok
blam! test lexers::json::tests::it_can_handle_utf8_data ... ok
blam! test lexers::ruby::tests::it_identifies_integers_and_operators ... ok
blam! test lexers::xml::tests::it_can_handle_garbage ... ok
blam! test lexers::ruby::tests::it_works ... ok
blam! test lexers::xml::tests::it_can_handle_utf8_data ... ok
blam! test lexers::json::tests::it_works ... ok
blam! test lexers::xml::tests::it_can_handle_open_strings ... ok
blam! test lexers::rust::tests::it_works ... ok
blam! test tokenizer::tests::current_char_returns_none_if_at_the_end ... ok
blam! test tokenizer::tests::tokenize_creates_the_correct_token ... ok
blam! test tokenizer::tests::consume_whitespace_handles_preexisting_noncategorized_chars ... ok
blam! test lexers::xml::tests::it_works ... ok
blam! test tokenizer::tests::current_char_returns_the_char_at_head ... ok
blam! test tokenizer::tests::tokenize_does_nothing_if_range_is_empty ... ok
blam! test tokenizer::tests::tokenize_next_takes_at_most_what_is_left ... ok
blam! test tokenizer::tests::tokens_joins_advanced_data_with_unprocessed_data_as_text_token ... ok
blam! test tokenizer::tests::tokenize_next_tokenizes_next_x_chars ... ok
blam! test tokenizer::tests::tokens_returns_unprocessed_data_as_text_token ... ok
blam! test tokenizer::tests::tokenize_next_tokenizes_previous_data_as_text ... ok
blam! 
blam! test result: ok. 27 passed; 0 failed; 0 ignored; 0 measured
blam! 
kablam!    Doc-tests luthor
blam! 
blam! running 10 tests
blam! test /source/src/tokenizer.rs - tokenizer::Tokenizer<'a>::has_prefix (line 163) ... ok
blam! test /source/src/tokenizer.rs - tokenizer::Tokenizer<'a>::advance (line 90) ... ok
blam! test /source/src/tokenizer.rs - tokenizer::Tokenizer<'a>::consume_whitespace (line 307) ... ok
blam! test /source/src/tokenizer.rs - tokenizer::Tokenizer<'a>::current_char (line 115) ... ok
blam! test /source/src/tokenizer.rs - tokenizer::Tokenizer<'a>::new (line 29) ... ok
blam! test /source/src/tokenizer.rs - tokenizer::Tokenizer<'a>::starts_with_lexeme (line 191) ... ok
blam! test /source/src/tokenizer.rs - tokenizer::Tokenizer<'a>::next_non_whitespace_char (line 139) ... ok
blam! test /source/src/tokenizer.rs - tokenizer::Tokenizer<'a>::tokenize (line 238) ... ok
blam! test /source/src/tokenizer.rs - tokenizer::Tokenizer<'a>::tokenize_next (line 270) ... ok
blam! test /source/src/tokenizer.rs - tokenizer::Tokenizer<'a>::tokens (line 48) ... ok
blam! 
blam! test result: ok. 10 passed; 0 failed; 0 ignored; 0 measured
blam! 
boom! running `docker rm -f 84ffc465f05ac96d4fbf88741c647d520a94a9f36529832ab4e619b299bcb027`
blam! 84ffc465f05ac96d4fbf88741c647d520a94a9f36529832ab4e619b299bcb027
