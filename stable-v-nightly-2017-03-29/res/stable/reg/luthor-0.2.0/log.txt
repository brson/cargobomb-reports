boom! testing luthor-0.2.0 against stable for nightly
boom! running: cargo +stable build --frozen
boom! creating container for: cargo +stable build --frozen
boom! running `docker create -v /home/ec2-user/cargobomb/./work/local/test-source/nightly/stable:/source:ro -v /home/ec2-user/cargobomb/./work/local/cargo-home:/cargo-home:ro -v /home/ec2-user/cargobomb/./work/local/rustup-home:/rustup-home:ro -v /home/ec2-user/cargobomb/./work/local/target-dirs/nightly/stable:/target:rw -e USER_ID=500 -e CMD=cargo +stable build --frozen cargobomb`
blam! 62e5e5cc180528646fcdf30650111d5d20f2ecd748403d092d75f67ad6ea1e1f
boom! running `docker start -a 62e5e5cc180528646fcdf30650111d5d20f2ecd748403d092d75f67ad6ea1e1f`
kablam!    Compiling luthor v0.2.0 (file:///source)
kablam!     Finished dev [unoptimized + debuginfo] target(s) in 1.14 secs
boom! running `docker rm -f 62e5e5cc180528646fcdf30650111d5d20f2ecd748403d092d75f67ad6ea1e1f`
blam! 62e5e5cc180528646fcdf30650111d5d20f2ecd748403d092d75f67ad6ea1e1f
boom! running: cargo +stable test --frozen --no-run
boom! creating container for: cargo +stable test --frozen --no-run
boom! running `docker create -v /home/ec2-user/cargobomb/./work/local/test-source/nightly/stable:/source:ro -v /home/ec2-user/cargobomb/./work/local/cargo-home:/cargo-home:ro -v /home/ec2-user/cargobomb/./work/local/rustup-home:/rustup-home:ro -v /home/ec2-user/cargobomb/./work/local/target-dirs/nightly/stable:/target:rw -e USER_ID=500 -e CMD=cargo +stable test --frozen --no-run cargobomb`
blam! 05071cde1dcad1665898bce83ee10f6771d36e62daa6364fbdff6c4cc3f90644
boom! running `docker start -a 05071cde1dcad1665898bce83ee10f6771d36e62daa6364fbdff6c4cc3f90644`
kablam!    Compiling luthor v0.2.0 (file:///source)
kablam!     Finished dev [unoptimized + debuginfo] target(s) in 1.59 secs
boom! running `docker rm -f 05071cde1dcad1665898bce83ee10f6771d36e62daa6364fbdff6c4cc3f90644`
blam! 05071cde1dcad1665898bce83ee10f6771d36e62daa6364fbdff6c4cc3f90644
boom! running: cargo +stable test --frozen
boom! creating container for: cargo +stable test --frozen
boom! running `docker create -v /home/ec2-user/cargobomb/./work/local/test-source/nightly/stable:/source:ro -v /home/ec2-user/cargobomb/./work/local/cargo-home:/cargo-home:ro -v /home/ec2-user/cargobomb/./work/local/rustup-home:/rustup-home:ro -v /home/ec2-user/cargobomb/./work/local/target-dirs/nightly/stable:/target:rw -e USER_ID=500 -e CMD=cargo +stable test --frozen cargobomb`
blam! 8480f6e930e88d2bf8a70b668e45cd21456d6fa9a521226d88b4a3980da46b1e
boom! running `docker start -a 8480f6e930e88d2bf8a70b668e45cd21456d6fa9a521226d88b4a3980da46b1e`
kablam!     Finished dev [unoptimized + debuginfo] target(s) in 0.0 secs
kablam!      Running /target/debug/deps/luthor-468bb436cd02ee02
blam! 
blam! running 22 tests
blam! test lexers::json::tests::it_can_handle_open_strings ... ok
blam! test lexers::json::tests::it_can_handle_utf8_data ... ok
blam! test lexers::default::tests::it_works ... ok
blam! test lexers::json::tests::it_can_handle_garbage ... ok
blam! test lexers::json::tests::it_works ... ok
blam! test lexers::ruby::tests::it_identifies_integers_and_operators ... ok
blam! test lexers::xml::tests::it_can_handle_open_strings ... ok
blam! test lexers::xml::tests::it_can_handle_utf8_data ... ok
blam! test lexers::xml::tests::it_can_handle_garbage ... ok
blam! test lexers::xml::tests::it_works ... ok
blam! test tokenizer::tests::current_char_returns_none_if_at_the_end ... ok
blam! test lexers::ruby::tests::it_works ... ok
blam! test tokenizer::tests::tokenize_creates_the_correct_token ... ok
blam! test tokenizer::tests::tokenize_does_nothing_if_range_is_empty ... ok
blam! test lexers::rust::tests::it_works ... ok
blam! test tokenizer::tests::tokenize_next_tokenizes_next_x_chars ... ok
blam! test tokenizer::tests::consume_whitespace_handles_preexisting_noncategorized_chars ... ok
blam! test tokenizer::tests::tokenize_next_takes_at_most_what_is_left ... ok
blam! test tokenizer::tests::current_char_returns_the_char_at_head ... ok
blam! test tokenizer::tests::tokens_joins_advanced_data_with_unprocessed_data_as_text_token ... ok
blam! test tokenizer::tests::tokenize_next_tokenizes_previous_data_as_text ... ok
blam! test tokenizer::tests::tokens_returns_unprocessed_data_as_text_token ... ok
blam! 
blam! test result: ok. 22 passed; 0 failed; 0 ignored; 0 measured
blam! 
kablam!    Doc-tests luthor
blam! 
blam! running 10 tests
blam! test tokenizer::Tokenizer<'a>::has_prefix_0 ... ok
blam! test tokenizer::Tokenizer<'a>::consume_whitespace_0 ... ok
blam! test tokenizer::Tokenizer<'a>::current_char_0 ... ok
blam! test tokenizer::Tokenizer<'a>::advance_0 ... ok
blam! test tokenizer::Tokenizer<'a>::starts_with_lexeme_0 ... ok
blam! test tokenizer::Tokenizer<'a>::tokenize_0 ... ok
blam! test tokenizer::Tokenizer<'a>::next_non_whitespace_char_0 ... ok
blam! test tokenizer::Tokenizer<'a>::new_0 ... ok
blam! test tokenizer::Tokenizer<'a>::tokenize_next_0 ... ok
blam! test tokenizer::Tokenizer<'a>::tokens_0 ... ok
blam! 
blam! test result: ok. 10 passed; 0 failed; 0 ignored; 0 measured
blam! 
boom! running `docker rm -f 8480f6e930e88d2bf8a70b668e45cd21456d6fa9a521226d88b4a3980da46b1e`
blam! 8480f6e930e88d2bf8a70b668e45cd21456d6fa9a521226d88b4a3980da46b1e
